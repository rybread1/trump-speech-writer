{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trump_speech_writer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOKoclpUzheC8fnZE08PHTS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rybread1/trump_speech_writer/blob/master/trump_speech_writer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYqId2KNgX1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import os"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vp-4AMHHWGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "88470db1-3230-4c7f-b90d-5b7b7d131d3a"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  4  903k    4 42501    0     0   532k      0  0:00:01 --:--:--  0:00:01  532k\r100  903k  100  903k    0     0  7402k      0 --:--:-- --:--:-- --:--:-- 7342k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McvkTbG5F69P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reading and processing text\n",
        "with open('speeches.txt', 'r') as fp:\n",
        "    text = fp.read()\n",
        "    \n",
        "start_indx = text.find('Thank you so much')\n",
        "\n",
        "text = text[start_indx:].lower()  # trimmed text doc\n",
        "char_set = set(text) # unique character set\n",
        "char_set_sorted = sorted(char_set)\n",
        "\n",
        "char_2_int_dict = {ch:i for i,ch in enumerate(char_set_sorted)} # dict mapping char to int\n",
        "char_array = np.array(char_set_sorted) # array mapping idx to char\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char_2_int_dict[ch] for ch in text],\n",
        "    dtype=np.int32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mjYtzdJIck-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "seq_length = 120 \n",
        "chunk_size = seq_length + 1\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True) \n",
        "\n",
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 200000\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "def get_test_train_split(text, chunk_size, batch_size, train_split=0.85):\n",
        "    return np.floor(len(text) / chunk_size / batch_size) * train_split\n",
        "\n",
        "train_batches = get_test_train_split(text_encoded, chunk_size, BATCH_SIZE)\n",
        "\n",
        "ds_train = ds.take(train_batches)\n",
        "ds_valid = ds.skip(train_batches)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x58f2dPbJC3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "d2a066dc-fa51-44a2-c5c4-d897afc8733c"
      },
      "source": [
        "\n",
        "def build_model(input_size, vocab_size, embedding_dim, rnn_units, dropout=True):\n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = tf.keras.layers.LSTM(rnn_units, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.LSTM(rnn_units, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = build_model(input_size=seq_length, vocab_size=len(char_array), \n",
        "                    embedding_dim=256, rnn_units=512)\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_29\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 120)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 120, 256)          16896     \n",
            "_________________________________________________________________\n",
            "lstm_18 (LSTM)               (None, 120, 512)          1574912   \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 120, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_19 (LSTM)               (None, 120, 512)          2099200   \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 120, 512)          0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 120, 66)           33858     \n",
            "=================================================================\n",
            "Total params: 3,724,866\n",
            "Trainable params: 3,724,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTnyDA4HV9d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6ab7688-c24e-4f48-9966-fad4ed8ae7a0"
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=0)\n",
        "\n",
        "results = model.fit(ds_train, validation_data=ds_valid, epochs=30, callbacks=[cp_callback])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "97/97 [==============================] - 19s 194ms/step - loss: 2.9861 - val_loss: 2.5049\n",
            "Epoch 2/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 2.2463 - val_loss: 1.9551\n",
            "Epoch 3/30\n",
            "97/97 [==============================] - 18s 188ms/step - loss: 1.8393 - val_loss: 1.6380\n",
            "Epoch 4/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.6041 - val_loss: 1.4659\n",
            "Epoch 5/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.4618 - val_loss: 1.3386\n",
            "Epoch 6/30\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.3695 - val_loss: 1.2610\n",
            "Epoch 7/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.3040 - val_loss: 1.2007\n",
            "Epoch 8/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.2495 - val_loss: 1.1509\n",
            "Epoch 9/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.2070 - val_loss: 1.1074\n",
            "Epoch 10/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.1740 - val_loss: 1.0936\n",
            "Epoch 11/30\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.1452 - val_loss: 1.0504\n",
            "Epoch 12/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.1191 - val_loss: 1.0285\n",
            "Epoch 13/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.0954 - val_loss: 1.0070\n",
            "Epoch 14/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.0728 - val_loss: 0.9719\n",
            "Epoch 15/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 1.0534 - val_loss: 0.9573\n",
            "Epoch 16/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.0367 - val_loss: 0.9308\n",
            "Epoch 17/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 1.0177 - val_loss: 0.9199\n",
            "Epoch 18/30\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 1.0018 - val_loss: 0.8920\n",
            "Epoch 19/30\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.9852 - val_loss: 0.8854\n",
            "Epoch 20/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.9705 - val_loss: 0.8670\n",
            "Epoch 21/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.9543 - val_loss: 0.8408\n",
            "Epoch 22/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.9381 - val_loss: 0.8317\n",
            "Epoch 23/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.9259 - val_loss: 0.8185\n",
            "Epoch 24/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 0.9108 - val_loss: 0.8007\n",
            "Epoch 25/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 0.8953 - val_loss: 0.7808\n",
            "Epoch 26/30\n",
            "97/97 [==============================] - 18s 186ms/step - loss: 0.8843 - val_loss: 0.7659\n",
            "Epoch 27/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.8685 - val_loss: 0.7468\n",
            "Epoch 28/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.8563 - val_loss: 0.7323\n",
            "Epoch 29/30\n",
            "97/97 [==============================] - 18s 184ms/step - loss: 0.8440 - val_loss: 0.7224\n",
            "Epoch 30/30\n",
            "97/97 [==============================] - 18s 185ms/step - loss: 0.8307 - val_loss: 0.7083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewli0cteLEt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, starting_str, \n",
        "           len_generated_text=500, \n",
        "           max_input_length=80,\n",
        "           scale_factor=1.0):\n",
        "    \n",
        "    starting_str = starting_str.lower()\n",
        "    encoded_input = [char_2_int_dict[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)        \n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(scaled_logits, num_samples=1)\n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()          \n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "        \n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "\n",
        "        encoded_input = tf.concat(\n",
        "            [encoded_input, new_char_indx],\n",
        "            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    return generated_str\n",
        "\n",
        "generated_text = generate_text(model, \n",
        "                               starting_str='build the wall', \n",
        "                               scale_factor=3, \n",
        "                               len_generated_text=4000,\n",
        "                               max_input_length=seq_length)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmEF68q6M8YH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc5c3300-9646-4695-dc5c-546e79bad02d"
      },
      "source": [
        "print(generated_text)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build the wall.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "the only one that was a big beautiful like this anymore. but i don’t know if you look at the border and the republicans and all of the people that are being doing that because of the people that are so incredible. they can’t get along with the world. they don’t want to do anything. i want to be a lot of people. they have a great respect.\n",
            "\n",
            "\n",
            "the people that are going to be so great to me.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " i want to keep our jobs and we’re going to be a lot of people. we’re going to be the stupid people. i’m the only one that said that i would have said, \"he’s a great company. i want to help the migration.\n",
            "i don’t know what’s going to happen. we have to be smart. we have to be smart. we have to stop it back in.\n",
            "and the other night i would have said, \"well, they don’t want to be able to do it. but if you want to do it. because we’re going to see the reasons that we’re going to do and they say, \"you know what i do is. i don’t know if it’s going to be a little bit doing. they don’t know what they’re doing. they have the worst than they can be the country and they’re going to be a lot of money. i mean, it’s going to be a very serious trouble. we’re going to carry about it.\n",
            "they want to do something about the polls. i love the people. i have to look at the deals and they are bad. they said, \"well, they don’t want to be proud of your country. we’re going to win at the border. we’re going to make our country so strong again.\n",
            "\n",
            "\n",
            "we will make our country rich again. we’re going to do what we’re going to do.\"\n",
            "and when i first people want to say a lot of people that are going to be a problem. and the press was a fantastic person. it’s a great second place and i said, \"what do you think? he said, \"donald, you know, i think they said \"donald trump is so important. they’re not going to be so strongly it we’re going to be saying that. we’re going to bring back our jobs. we’re going to bring them back. we love our country. they’re going to be so great to me.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " i want to begin and so and so great again. i mean, it’s a movement of money. it’s a movement. i think it’s going to be here.\n",
            "\n",
            "\n",
            "they want to start people to have the level out of the country. they can’t get the money because they were talking about the same thing. they can’t get the people that come into the country that we have to do it. we have to do it. we don’t want to do things with them. we have to do it.\n",
            "\n",
            "\n",
            "the bottom line is that they say \"well, we’re going to start thinking about it. you know, we have to get the oil. and they are so much money that we have to do it. you know, i said \"i think they have the greatest special interests or the people in the country and they are the friends of mine who is a total disaster. it’s a movement that is a statement that is going to be a couple of months ago, they have no choice. we have to do it.\n",
            "we have to rebuild our infrastructure.\n",
            "\n",
            "\n",
            "the biggest shoried is on the country.\n",
            "we have a strong people. i love the people. i want to thank my borders. i mean, they have the oil is on the country. we can’t see that.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "well, i think it’s going to be president of that building it because they’re not going to be able to do that. i don’t know what they’re doing. i said, \"well, they don’t want to be tough. i don’t know if i don’t want to be a great feeling.\n",
            "i want to thank all of the people in the world. they are ripping us off of all to be a great job. and they said, \"well, we’re going to do it.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "well, i think we’re going to do it.\n",
            "it’s not going to happen.\n",
            "if i don’t want to do it. he’s a very successful person. i have to say this. i don’t know if i don’t win, it’s a great company. it’s going to be so strong and so great. i want to thank my family. it’s an incredible company. it’s an amazing person. it’s not going to happen. it’s going to be a lot of things.\n",
            "but it’s a movement of money of the people that are saying it we all about the border. i was a big father. i mean, it’s a movement.\n",
            "now, the press was a story that’s concerned, she’s been a \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}