{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trump_speech_writer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZhlMFgopfecKa6PU88NL+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rybread1/trump_speech_writer/blob/master/trump_speech_writer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYqId2KNgX1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vp-4AMHHWGA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "88470db1-3230-4c7f-b90d-5b7b7d131d3a"
      },
      "source": [
        "!curl -O https://raw.githubusercontent.com/ryanmcdermott/trump-speeches/master/speeches.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  4  903k    4 42501    0     0   532k      0  0:00:01 --:--:--  0:00:01  532k\r100  903k  100  903k    0     0  7402k      0 --:--:-- --:--:-- --:--:-- 7342k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McvkTbG5F69P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Reading and processing text\n",
        "with open('speeches.txt', 'r') as fp:\n",
        "    text = fp.read()\n",
        "    \n",
        "start_indx = text.find('Thank you so much')\n",
        "\n",
        "text = text[start_indx:].lower()  # trimmed text doc\n",
        "char_set = set(text) # unique character set\n",
        "char_set_sorted = sorted(char_set)\n",
        "\n",
        "char_2_int_dict = {ch:i for i,ch in enumerate(char_set_sorted)} # dict mapping char to int\n",
        "char_array = np.array(char_set_sorted) # array mapping idx to char\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char_2_int_dict[ch] for ch in text],\n",
        "    dtype=np.int32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mjYtzdJIck-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "seq_length = 40 \n",
        "chunk_size = seq_length + 1\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True) \n",
        "\n",
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)\n",
        "\n",
        "# Batch size\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 200000\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "def get_test_train_split(text, chunk_size, batch_size, train_split=0.9):\n",
        "    return np.floor(len(text) / chunk_size / batch_size) * train_split\n",
        "\n",
        "train_batches = get_test_train_split(text_encoded, chunk_size, BATCH_SIZE)\n",
        "\n",
        "ds_train = ds.take(train_batches)\n",
        "ds_valid = ds.skip(train_batches)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x58f2dPbJC3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "c0e18d7d-8a4b-40e3-aeae-6fddd47301c4"
      },
      "source": [
        "def build_model(input_size, vocab_size, embedding_dim, rnn_units, dropout=True):\n",
        "    inputs = tf.keras.Input(input_size)\n",
        "    x = tf.keras.layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    x = tf.keras.layers.LSTM(rnn_units, return_sequences=True)(x)\n",
        "    x = tf.keras.layers.LSTM(rnn_units, return_sequences=True)(x)\n",
        "    if dropout:\n",
        "        x = tf.keras.layers.Dropout(0.5)(x)\n",
        "    outputs = tf.keras.layers.Dense(vocab_size)(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = build_model(input_size=seq_length, vocab_size=len(char_array), \n",
        "                    embedding_dim=256, rnn_units=512)\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 40)]              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 40, 256)           16896     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 40, 512)           1574912   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 40, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 40, 512)           0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 40, 66)            33858     \n",
            "=================================================================\n",
            "Total params: 3,724,866\n",
            "Trainable params: 3,724,866\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTnyDA4HV9d8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "1b2af25b-4a1c-4695-d882-b6c8491e7b49"
      },
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=0)\n",
        "\n",
        "results = model.fit(ds_train, validation_data=ds_valid, epochs=20, callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "614/614 [==============================] - 31s 50ms/step - loss: 2.1507 - val_loss: 1.5313\n",
            "Epoch 2/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.4562 - val_loss: 1.2832\n",
            "Epoch 3/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.3033 - val_loss: 1.1709\n",
            "Epoch 4/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.2251 - val_loss: 1.1219\n",
            "Epoch 5/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.1725 - val_loss: 1.0728\n",
            "Epoch 6/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.1331 - val_loss: 1.0307\n",
            "Epoch 7/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.1007 - val_loss: 1.0065\n",
            "Epoch 8/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.0733 - val_loss: 0.9746\n",
            "Epoch 9/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.0470 - val_loss: 0.9547\n",
            "Epoch 10/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.0225 - val_loss: 0.9244\n",
            "Epoch 11/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 1.0005 - val_loss: 0.9075\n",
            "Epoch 12/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 0.9811 - val_loss: 0.8887\n",
            "Epoch 13/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 0.9600 - val_loss: 0.8576\n",
            "Epoch 14/20\n",
            "614/614 [==============================] - 30s 49ms/step - loss: 0.9420 - val_loss: 0.8367\n",
            "Epoch 15/20\n",
            "405/614 [==================>...........] - ETA: 9s - loss: 0.9182"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewli0cteLEt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, starting_str, \n",
        "           len_generated_text=500, \n",
        "           max_input_length=80,\n",
        "           scale_factor=1.0):\n",
        "    \n",
        "    starting_str = starting_str.lower()\n",
        "    encoded_input = [char_2_int_dict[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)        \n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(scaled_logits, num_samples=1)\n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()          \n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "        \n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "\n",
        "        encoded_input = tf.concat(\n",
        "            [encoded_input, new_char_indx],\n",
        "            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    return generated_str\n",
        "\n",
        "generated_text = generate_text(model, \n",
        "                               starting_str='we are going to make america great again!', \n",
        "                               scale_factor=3, \n",
        "                               len_generated_text=300)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmEF68q6M8YH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "05212712-d01a-4d16-cdfa-6906cfd8da7f"
      },
      "source": [
        "print(generated_text)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we are going to make america great again! we have a very sergeant bergdahl, read the air conditioners is not a politician fighting and i said that in a landslide. and i said, \"what about the hell out of the other candidates who i did a great job in free trade. i think itâ€™s going to be a lot of money to be a members makers in the world and \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXzEIs91aAF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}